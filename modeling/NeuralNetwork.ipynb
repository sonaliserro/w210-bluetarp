{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and packages\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Modeling\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitinserro/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (29,30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3533663 records combined.\n"
     ]
    }
   ],
   "source": [
    "femaTrainData = pd.read_csv('../data/open-fema/FEMA-Large-Demographics-FL-TX.csv')\n",
    "print('There are {} records combined.'.format(len(femaTrainData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disasterNumber', 'damagedCity', 'damagedStateAbbreviation',\n",
       "       'damagedZipCode', 'householdComposition', 'grossIncome', 'specialNeeds',\n",
       "       'homeOwnersInsurance', 'floodInsurance', 'inspected', 'rpfvl',\n",
       "       'habitabilityRepairsRequired', 'destroyed', 'waterLevel', 'floodDamage',\n",
       "       'foundationDamage', 'foundationDamageAmount', 'roofDamage',\n",
       "       'roofDamageAmount', 'tsaEligible', 'tsaCheckedIn',\n",
       "       'rentalAssistanceEligible', 'rentalAssistanceAmount',\n",
       "       'repairAssistanceEligible', 'repairAmount',\n",
       "       'replacementAssistanceEligible', 'replacementAmount', 'sbaEligible',\n",
       "       'renterDamageLevel', 'rentalAssistanceEndDate', 'rentalResourceCity',\n",
       "       'rentalResourceStateAbbreviation', 'rentalResourceZipCode',\n",
       "       'primaryResidence', 'personalPropertyEligible', 'ppfvl',\n",
       "       'censusBlockId', 'censusYear', 'id', 'censusTractId', 'censusid',\n",
       "       'tractid', 'tractname', 'county', 'state', 'below_poverty_rate',\n",
       "       'median_earnings_total', 'unemployed_labor_rate',\n",
       "       'built_1979_or_earlier_rate', 'owner_occupied_rate', 'dvi', 'haAmount',\n",
       "       'ownRent_Owner', 'ownRent_Renter', 'ownRent_Unknown',\n",
       "       'residenceType_Apartment', 'residenceType_Assisted Living Facility',\n",
       "       'residenceType_Boat', 'residenceType_College Dorm',\n",
       "       'residenceType_Condo', 'residenceType_Correctional Facility',\n",
       "       'residenceType_House/Duplex', 'residenceType_Military Housing',\n",
       "       'residenceType_Mobile Home', 'residenceType_Other',\n",
       "       'residenceType_Townhouse', 'residenceType_Travel Trailer',\n",
       "       'residenceType_Unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaTrainData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a subset of columns\n",
    "https://docs.google.com/document/d/1nu0yENGAWnoiMcTufxYnH7xwdh8NfFum9ni9IYiSIdk/edit#\n",
    "https://docs.google.com/document/d/1cpznnaIb5CE21I2RO8y2xRvZKS8StcP_JeXDW2mUIis/edit?ts=60319d34#heading=h.j8u0tgugtaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of columns (No demographics)\n",
    "ihp_exclude_cols = ['disasterNumber', \n",
    "                    'damagedCity', \n",
    "                    'damagedStateAbbreviation',\n",
    "                    'damagedZipCode',\n",
    "                    'grossIncome',\n",
    "                    'foundationDamageAmount',\n",
    "                    'roofDamageAmount',\n",
    "                    'tsaCheckedIn',\n",
    "                    'rentalAssistanceAmount',\n",
    "                    'repairAmount',\n",
    "                    'replacementAmount',\n",
    "                    'renterDamageLevel', \n",
    "                    'rentalAssistanceEndDate', \n",
    "                    'rentalResourceCity',\n",
    "                    'rentalResourceStateAbbreviation', \n",
    "                    'rentalResourceZipCode',\n",
    "                    'personalPropertyEligible', \n",
    "                    'ppfvl',\n",
    "                    'censusBlockId', \n",
    "                    'censusYear', \n",
    "                    'id']\n",
    "demo_exclude_cols = ['censusTractId', \n",
    "                     'censusid',\n",
    "                     'tractid', \n",
    "                     'tractname', \n",
    "                     'county', \n",
    "                     'state',\n",
    "                     'median_earnings_total',]\n",
    "demo_dvi_col = ['dvi']\n",
    "demo_rate_cols = ['below_poverty_rate',\n",
    "                  'unemployed_labor_rate',\n",
    "                  'built_1979_or_earlier_rate', \n",
    "                  'owner_occupied_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp(df, frac):\n",
    "    # Sample the dataset\n",
    "    df_train = df.sample(frac=frac) if frac < 1.0 else df    \n",
    "        \n",
    "    # Create test/train split\n",
    "    X = df_train.loc[:, df_train.columns != 'haAmount']\n",
    "    y = df_train.loc[:, 'haAmount']    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42)\n",
    "    \n",
    "    # Scale the numeric fields\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Define the model\n",
    "    model_mlp = MLPRegressor(hidden_layer_sizes=(15, 10, 5), activation='relu', \n",
    "                 learning_rate='constant', learning_rate_init=0.008, \n",
    "                 random_state=42, solver='adam', max_iter=300)\n",
    "    \n",
    "    # Fit the model\n",
    "    model_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    return (model_mlp, model_mlp.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp_grid_search(df, frac):\n",
    "    # Sample the dataset\n",
    "    df_train = df.sample(frac=frac) if frac < 1.0 else df    \n",
    "        \n",
    "    # Create test/train split\n",
    "    X = df_train.loc[:, df_train.columns != 'haAmount']\n",
    "    y = df_train.loc[:, 'haAmount']    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42)\n",
    "    \n",
    "    # Scale the numeric fields\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # MLPRegressor default model\n",
    "    model_mlp = MLPRegressor(random_state = 42)\n",
    "    \n",
    "    # Create the parameter grid\n",
    "    param_grid_mlp = {\n",
    "        'solver' : ['adam'],\n",
    "        'activation': ['relu'],\n",
    "        'learning_rate_init': [0.008, 0.01],\n",
    "        'learning_rate' : ['constant', 'adaptive'],\n",
    "        'max_iter' : [300, 400, 500],\n",
    "        'hidden_layer_sizes' : [(15, 10, 5), (15, 5, 5), (10, 5, 5)]\n",
    "    }\n",
    "    \n",
    "    # Instantiate the grid search model\n",
    "    grid_search_mlp = GridSearchCV(estimator = model_mlp, param_grid = param_grid_mlp, \n",
    "                                   scoring='neg_mean_absolute_error', cv = 3, n_jobs = -1, verbose = 2)    \n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best params:\\n', grid_search_mlp.best_params_)\n",
    "    \n",
    "    # Predict using best model\n",
    "    model_mlp_best = grid_search_mlp.best_estimator_\n",
    "    \n",
    "    return (model_mlp_best, model_mlp_best.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('R-squared:', metrics.r2_score(y_test, y_pred))\n",
    "    print('\\n')\n",
    "    print('Total HA Amount actual:    ${:,.2f}'.format(y_test.sum()))\n",
    "    print('Total HA Amount predicted: ${:,.2f}'.format(y_pred.sum()))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Calculate the number of observations that are off by more than 20%\n",
    "    results_df = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "    results_df['diff'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['percent_diff'] = (abs(abs(results_df['predicted'] / (results_df['actual'])) - 1) * 100).where(results_df['actual'] > 0, 0)\n",
    "    print('Percentage of predictions that are off by more than 20%: {:.2f}'.format( \n",
    "          len(results_df[results_df['percent_diff'] > 20])/len(results_df) * 100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IHP - No Demographics - Learning Rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaDf = femaTrainData[femaTrainData.columns[~femaTrainData.columns.isin(\n",
    "    ihp_exclude_cols + demo_exclude_cols + demo_dvi_col + demo_rate_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp, y_pred, y_test = run_mlp(femaDf, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 76.67466922814468\n",
      "Mean Squared Error: 312161.2357454662\n",
      "Root Mean Squared Error: 558.7139122533698\n",
      "R-squared: 0.9503545384394623\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $385,808,834.81\n",
      "Total HA Amount predicted: $380,428,831.67\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 4.87\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IHP - No Demographics - Learning Rate 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaDf = femaTrainData[femaTrainData.columns[~femaTrainData.columns.isin(\n",
    "    ihp_exclude_cols + demo_exclude_cols + demo_dvi_col + demo_rate_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp, y_pred, y_test = run_mlp(femaDf, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 79.62948180089535\n",
      "Mean Squared Error: 319310.21712897916\n",
      "Root Mean Squared Error: 565.0754083562468\n",
      "R-squared: 0.9492175795866931\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $385,808,834.81\n",
      "Total HA Amount predicted: $385,179,175.88\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 5.25\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IHP - with DVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaDf = femaTrainData[femaTrainData.columns[~femaTrainData.columns.isin(\n",
    "    ihp_exclude_cols + demo_exclude_cols + demo_rate_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp, y_pred, y_test = run_mlp(femaDf, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 91.16777553572913\n",
      "Mean Squared Error: 335289.9008132428\n",
      "Root Mean Squared Error: 579.0422271417196\n",
      "R-squared: 0.9466762045495198\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $385,808,834.81\n",
      "Total HA Amount predicted: $405,418,588.13\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 5.87\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IHP - with rate demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaDf = femaTrainData[femaTrainData.columns[~femaTrainData.columns.isin(\n",
    "    ihp_exclude_cols + demo_exclude_cols + demo_dvi_col)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp, y_pred, y_test = run_mlp(femaDf, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 77.8405918101761\n",
      "Mean Squared Error: 320196.253444546\n",
      "Root Mean Squared Error: 565.8588635380257\n",
      "R-squared: 0.9490766662483002\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $385,808,834.81\n",
      "Total HA Amount predicted: $387,586,600.55\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 5.20\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search - IHP Only, 0.5 data due to time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaDf = femaTrainData[femaTrainData.columns[~femaTrainData.columns.isin(\n",
    "    ihp_exclude_cols + demo_exclude_cols + demo_dvi_col + demo_rate_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best params:\n",
      " {'activation': 'relu', 'hidden_layer_sizes': (15, 10, 5), 'learning_rate': 'constant', 'learning_rate_init': 0.008, 'max_iter': 300, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "model_mlp, y_pred, y_test = run_mlp_grid_search(femaDf, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 78.44164053677102\n",
      "Mean Squared Error: 347239.98531831946\n",
      "Root Mean Squared Error: 589.2707232828723\n",
      "R-squared: 0.9459570569394383\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $193,860,176.64\n",
      "Total HA Amount predicted: $188,011,821.32\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 5.34\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3400246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901899</th>\n",
       "      <td>1014.0</td>\n",
       "      <td>1020.344917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809092</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181447</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977809</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706733 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Actual    Predicted\n",
       "3400246     0.0     0.097991\n",
       "901899   1014.0  1020.344917\n",
       "3226677     0.0     0.097991\n",
       "1347233     0.0     0.097991\n",
       "1809092     0.0     0.097991\n",
       "...         ...          ...\n",
       "3181447     0.0     0.097991\n",
       "1977809     0.0     0.097991\n",
       "2151645     0.0     0.097991\n",
       "2406434     0.0     0.097991\n",
       "2165864     0.0     0.097991\n",
       "\n",
       "[706733 rows x 2 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at actual verus predicted\n",
    "df = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(model_mlp, open('mlp.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (15, 10, 5),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.008,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 300,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 42,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "model_mlp_sav = pickle.load(open('mlp.sav', 'rb'))\n",
    "model_mlp_sav.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
