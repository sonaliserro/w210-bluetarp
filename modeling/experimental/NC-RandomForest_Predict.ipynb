{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and packages\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# Save models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Test Dataset - NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 132384 records in our test dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rossm\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (29,30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "femaTestData = pd.read_csv('../../data/open-fema/FEMA-Large-NC-clean.csv')\n",
    "print('There are {} records in our test dataset.'.format(len(femaTestData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disasterNumber', 'damagedCity', 'damagedStateAbbreviation',\n",
       "       'damagedZipCode', 'householdComposition', 'grossIncome', 'specialNeeds',\n",
       "       'homeOwnersInsurance', 'floodInsurance', 'inspected', 'rpfvl',\n",
       "       'habitabilityRepairsRequired', 'destroyed', 'waterLevel', 'floodDamage',\n",
       "       'foundationDamage', 'foundationDamageAmount', 'roofDamage',\n",
       "       'roofDamageAmount', 'tsaEligible', 'tsaCheckedIn',\n",
       "       'rentalAssistanceEligible', 'rentalAssistanceAmount',\n",
       "       'repairAssistanceEligible', 'repairAmount',\n",
       "       'replacementAssistanceEligible', 'replacementAmount', 'sbaEligible',\n",
       "       'renterDamageLevel', 'rentalAssistanceEndDate', 'rentalResourceCity',\n",
       "       'rentalResourceStateAbbreviation', 'rentalResourceZipCode',\n",
       "       'primaryResidence', 'personalPropertyEligible', 'ppfvl',\n",
       "       'censusBlockId', 'censusYear', 'id', 'censusTractId', 'tractid',\n",
       "       'haAmount', 'ownRent_Owner', 'ownRent_Renter', 'ownRent_Unknown',\n",
       "       'residenceType_Apartment', 'residenceType_Assisted Living Facility',\n",
       "       'residenceType_Boat', 'residenceType_College Dorm',\n",
       "       'residenceType_Condo', 'residenceType_Correctional Facility',\n",
       "       'residenceType_House/Duplex', 'residenceType_Military Housing',\n",
       "       'residenceType_Mobile Home', 'residenceType_Other',\n",
       "       'residenceType_Townhouse', 'residenceType_Travel Trailer',\n",
       "       'residenceType_Unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaTestData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a subset of columns\n",
    "\n",
    "IHP: https://docs.google.com/document/d/1nu0yENGAWnoiMcTufxYnH7xwdh8NfFum9ni9IYiSIdk/edit#\n",
    "\n",
    "Demographics: https://docs.google.com/document/d/1cpznnaIb5CE21I2RO8y2xRvZKS8StcP_JeXDW2mUIis/edit?ts=60319d34#heading=h.j8u0tgugtaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihp_exclude_cols = ['disasterNumber', \n",
    "                    'damagedCity', \n",
    "                    'damagedStateAbbreviation',\n",
    "                    'damagedZipCode',\n",
    "                    'grossIncome',\n",
    "                    'foundationDamageAmount',\n",
    "                    'roofDamageAmount',\n",
    "                    'tsaCheckedIn',\n",
    "                    'rentalAssistanceAmount',\n",
    "                    'repairAmount',\n",
    "                    'replacementAmount',\n",
    "                    'renterDamageLevel', \n",
    "                    'rentalAssistanceEndDate', \n",
    "                    'rentalResourceCity',\n",
    "                    'rentalResourceStateAbbreviation', \n",
    "                    'rentalResourceZipCode',\n",
    "                    'personalPropertyEligible', \n",
    "                    'ppfvl',\n",
    "                    'censusBlockId', \n",
    "                    'censusYear', \n",
    "                    'id']\n",
    "demo_exclude_cols = ['censusTractId', \n",
    "                     'censusid',\n",
    "                     'tractid', \n",
    "                     'tractname', \n",
    "                     'county', \n",
    "                     'state',\n",
    "                     'median_earnings_total',]\n",
    "demo_dvi_col = ['dvi']\n",
    "demo_rate_cols = ['below_poverty_rate',\n",
    "                  'unemployed_labor_rate',\n",
    "                  'built_1979_or_earlier_rate', \n",
    "                  'owner_occupied_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest\n",
    "\n",
    "https://machinelearningmastery.com/random-forest-ensemble-in-python/\n",
    "\n",
    "- The “max_samples” argument can be set to a float between 0 and 1 to control the percentage of the size of the training dataset to make the bootstrap sample used to train each decision tree.\n",
    "- max_features argument and defaults to the square root of the number of input features. \n",
    "- The number of trees can be set via the “n_estimators” argument and defaults to 100.\n",
    "- The maximum tree depth can be specified via the max_depth argument and is set to None (no maximum depth) by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(df, frac, max_depth, max_samples, n_estimators, min_samples_leaf):\n",
    "    # Sample the dataset\n",
    "    df_train = df.sample(frac=frac) if frac < 1.0 else df    \n",
    "        \n",
    "    # Create test/train split\n",
    "    X = df_train.loc[:, df_train.columns != 'haAmount']\n",
    "    y = df_train.loc[:, 'haAmount']    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42) \n",
    "  \n",
    "    print('Shape of Training and Test inputs')\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    # Define the model\n",
    "    model_rf = RandomForestRegressor(max_depth = max_depth, max_samples = max_samples, n_estimators = n_estimators, \n",
    "                                     min_samples_leaf = min_samples_leaf, random_state = 42)\n",
    "    \n",
    "    # Fit the model\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    \n",
    "    return (model_rf, model_rf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_grid_search(df, frac):\n",
    "    # Sample the dataset\n",
    "    df_train = df.sample(frac=frac) if frac < 1.0 else df    \n",
    "        \n",
    "    # Create test/train split\n",
    "    X = df_train.loc[:, df_train.columns != 'haAmount']\n",
    "    y = df_train.loc[:, 'haAmount']    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42)\n",
    "    \n",
    "    print('Shape of Training and Test inputs')\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    # RandomForestRegressor default model\n",
    "    model_rf = RandomForestRegressor(random_state = 42)\n",
    "    \n",
    "    # Create the parameter grid\n",
    "    param_grid_rf = {\n",
    "        'bootstrap': [True],\n",
    "        'max_samples': [0.8, 0.9, None],\n",
    "        'max_depth': [8, 9, 10],\n",
    "        'n_estimators': [75, 100, 125],\n",
    "        'min_samples_leaf': [1, 5, 10]\n",
    "    }\n",
    "    \n",
    "    # Instantiate the grid search model\n",
    "    grid_search_rf = GridSearchCV(estimator = model_rf, param_grid = param_grid_rf, \n",
    "                                  scoring='neg_mean_squared_error', cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best params:\\n', grid_search_rf.best_params_)\n",
    "    \n",
    "    # Predict using best model\n",
    "    model_rf_best = grid_search_rf.best_estimator_\n",
    "    \n",
    "    return (model_rf_best, model_rf_best.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('R-squared:', metrics.r2_score(y_test, y_pred))\n",
    "    print('\\n')\n",
    "    print('Total HA Amount actual:    ${:,.2f}'.format(y_test.sum()))\n",
    "    print('Total HA Amount predicted: ${:,.2f}'.format(y_pred.sum()))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Calculate the number of observations that are off by more than 20%\n",
    "    results_df = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "    results_df['diff'] = results_df['predicted'] - results_df['actual']    \n",
    "    results_df['percent_diff'] = (abs(abs(results_df['predicted'] / (results_df['actual'])) - 1) * 100).where(results_df['actual'] > 0, 0)    \n",
    "    print('Percentage of predictions that are off by more than 20%: {:.2f}'.format( \n",
    "          len(results_df[results_df['percent_diff'] > 20])/len(results_df) * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, model):\n",
    "    X_test = df.loc[:, df.columns != 'haAmount']\n",
    "    y_test = df.loc[:, 'haAmount']    \n",
    "  \n",
    "    print('Shape of Training and Test inputs')    \n",
    "    print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    return (model.predict(X_test), y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IHP-only Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaTestDf = femaTestData[femaTestData.columns[~femaTestData.columns.isin(\n",
    "    ihp_exclude_cols + demo_exclude_cols + demo_dvi_col + demo_rate_cols)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Model2 - Hyperparameters based on current grid search\n",
    "    max_depth = 10, max_samples = 0.9, n_estimators = 125, \n",
    "    min_samples_leaf = 5, random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training and Test inputs\n",
      "(2549828, 34) (2549828,)\n",
      "(637457, 34) (637457,)\n"
     ]
    }
   ],
   "source": [
    "# model_rf2, y_pred, y_test = run_rf(femaDf, frac = 1.0, max_depth = 10, max_samples = 0.9, \n",
    "#                                   n_estimators = 125, min_samples_leaf = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(femaTestDf, model_rf_sav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 62.8185168269257\n",
      "Mean Squared Error: 333776.8924875107\n",
      "Root Mean Squared Error: 577.7342749807308\n",
      "R-squared: 0.9518735085349349\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $306,323,367.07\n",
      "Total HA Amount predicted: $305,457,100.07\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 2.74\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>637457.0</td>\n",
       "      <td>480.539655</td>\n",
       "      <td>2633.518498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td>637457.0</td>\n",
       "      <td>479.180713</td>\n",
       "      <td>2561.189489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32649.353177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errors</th>\n",
       "      <td>637457.0</td>\n",
       "      <td>-1.358942</td>\n",
       "      <td>577.733130</td>\n",
       "      <td>-33300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30262.173749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean          std      min  25%  50%  75%  \\\n",
       "actual     637457.0  480.539655  2633.518498      0.0  0.0  0.0  0.0   \n",
       "predicted  637457.0  479.180713  2561.189489      0.0  0.0  0.0  0.0   \n",
       "errors     637457.0   -1.358942   577.733130 -33300.0  0.0  0.0  0.0   \n",
       "\n",
       "                    max  \n",
       "actual     33300.000000  \n",
       "predicted  32649.353177  \n",
       "errors     30262.173749  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "results_df['errors'] = results_df['predicted'] - results_df['actual']\n",
    "results_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.9,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 125,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test (NC) using RandomForest Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': 0.9,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 125,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model_rf2 = pickle.load(open('./models/random_forest.sav', 'rb'))\n",
    "\n",
    "model_rf2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training and Test inputs\n",
      "(132384, 34) (132384,)\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_test = predict(femaTestDf, model_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 151.08004639575432\n",
      "Mean Squared Error: 641588.6873988011\n",
      "Root Mean Squared Error: 800.9923141945877\n",
      "R-squared: 0.8985953064009858\n",
      "\n",
      "\n",
      "Total HA Amount actual:    $84,945,334.78\n",
      "Total HA Amount predicted: $100,564,941.41\n",
      "\n",
      "\n",
      "Percentage of predictions that are off by more than 20%: 10.13\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>132384.0</td>\n",
       "      <td>641.658620</td>\n",
       "      <td>2515.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33267.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td>132384.0</td>\n",
       "      <td>759.645738</td>\n",
       "      <td>2684.142262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32547.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errors</th>\n",
       "      <td>132384.0</td>\n",
       "      <td>117.987118</td>\n",
       "      <td>792.257830</td>\n",
       "      <td>-23798.135914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31235.6247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean          std           min  25%  50%  75%  \\\n",
       "actual     132384.0  641.658620  2515.364693      0.000000  0.0  0.0  0.0   \n",
       "predicted  132384.0  759.645738  2684.142262      0.000000  0.0  0.0  0.0   \n",
       "errors     132384.0  117.987118   792.257830 -23798.135914  0.0  0.0  0.0   \n",
       "\n",
       "                  max  \n",
       "actual     33267.0000  \n",
       "predicted  32547.1247  \n",
       "errors     31235.6247  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "results_df['errors'] = results_df['predicted'] - results_df['actual']\n",
    "results_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction Files using RandomForest Model2 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append predictions to femaTestData\n",
    "femaTestData['haAmount_predicted'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disasterNumber', 'damagedCity', 'damagedStateAbbreviation',\n",
       "       'damagedZipCode', 'householdComposition', 'grossIncome', 'specialNeeds',\n",
       "       'homeOwnersInsurance', 'floodInsurance', 'inspected', 'rpfvl',\n",
       "       'habitabilityRepairsRequired', 'destroyed', 'waterLevel', 'floodDamage',\n",
       "       'foundationDamage', 'foundationDamageAmount', 'roofDamage',\n",
       "       'roofDamageAmount', 'tsaEligible', 'tsaCheckedIn',\n",
       "       'rentalAssistanceEligible', 'rentalAssistanceAmount',\n",
       "       'repairAssistanceEligible', 'repairAmount',\n",
       "       'replacementAssistanceEligible', 'replacementAmount', 'sbaEligible',\n",
       "       'renterDamageLevel', 'rentalAssistanceEndDate', 'rentalResourceCity',\n",
       "       'rentalResourceStateAbbreviation', 'rentalResourceZipCode',\n",
       "       'primaryResidence', 'personalPropertyEligible', 'ppfvl',\n",
       "       'censusBlockId', 'censusYear', 'id', 'censusTractId', 'tractid',\n",
       "       'haAmount', 'ownRent_Owner', 'ownRent_Renter', 'ownRent_Unknown',\n",
       "       'residenceType_Apartment', 'residenceType_Assisted Living Facility',\n",
       "       'residenceType_Boat', 'residenceType_College Dorm',\n",
       "       'residenceType_Condo', 'residenceType_Correctional Facility',\n",
       "       'residenceType_House/Duplex', 'residenceType_Military Housing',\n",
       "       'residenceType_Mobile Home', 'residenceType_Other',\n",
       "       'residenceType_Townhouse', 'residenceType_Travel Trailer',\n",
       "       'residenceType_Unknown', 'haAmount_predicted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaTestData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NC Prediction Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132384\n"
     ]
    }
   ],
   "source": [
    "# Write predictions\n",
    "femaTestData.to_csv(\"./predictions/FEMA-Large-NC-clean-predictions.csv\", index=False, encoding='utf-8')\n",
    "print(len(femaTestData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions - zipped\n",
    "#femaTestData.to_csv(\"./predictions/FEMA-Large-NC-clean-predictions.csv.gz\", index=False, encoding='utf-8', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rollup aggregations to censusTractId\n",
    "femaTestData_CensusTract = femaTestData.groupby(['censusTractId',]).agg({\n",
    "                                           'id': ['count'], \n",
    "                                           'grossIncome': ['mean'],\n",
    "                                           'householdComposition': ['mean'],                                           \n",
    "                                           'specialNeeds': ['sum'], \n",
    "                                           'homeOwnersInsurance': ['sum'],\n",
    "                                           'floodInsurance': ['sum'],\n",
    "                                           'inspected': ['sum'],\n",
    "                                           'rpfvl': ['sum'],\n",
    "                                           'habitabilityRepairsRequired': ['sum'],\n",
    "                                           'destroyed': ['sum'],\n",
    "                                           'waterLevel': ['mean'],\n",
    "                                           'floodDamage': ['sum'],\n",
    "                                           'foundationDamage': ['sum'], \n",
    "                                           'foundationDamageAmount': ['sum'], \n",
    "                                           'roofDamage': ['sum'],\n",
    "                                           'roofDamageAmount': ['sum'], \n",
    "                                           'tsaEligible': ['sum'], \n",
    "                                           'tsaCheckedIn': ['sum'],\n",
    "                                           'rentalAssistanceEligible': ['sum'], \n",
    "                                           'rentalAssistanceAmount': ['sum'], \n",
    "                                           'repairAssistanceEligible': ['sum'],\n",
    "                                           'repairAmount': ['sum'],\n",
    "                                           'replacementAssistanceEligible': ['sum'], \n",
    "                                           'replacementAmount': ['sum'], \n",
    "                                           'sbaEligible': ['sum'],\n",
    "                                           'primaryResidence': ['sum'], \n",
    "                                           'personalPropertyEligible': ['sum'], \n",
    "                                           'ppfvl': ['sum'],\n",
    "                                           'haAmount': ['sum'],\n",
    "                                           'haAmount_predicted': ['sum']\n",
    "                                          }).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grossIncome</th>\n",
       "      <th>householdComposition</th>\n",
       "      <th>specialNeeds</th>\n",
       "      <th>homeOwnersInsurance</th>\n",
       "      <th>floodInsurance</th>\n",
       "      <th>inspected</th>\n",
       "      <th>rpfvl</th>\n",
       "      <th>habitabilityRepairsRequired</th>\n",
       "      <th>destroyed</th>\n",
       "      <th>waterLevel</th>\n",
       "      <th>floodDamage</th>\n",
       "      <th>foundationDamage</th>\n",
       "      <th>foundationDamageAmount</th>\n",
       "      <th>roofDamage</th>\n",
       "      <th>roofDamageAmount</th>\n",
       "      <th>tsaEligible</th>\n",
       "      <th>tsaCheckedIn</th>\n",
       "      <th>rentalAssistanceEligible</th>\n",
       "      <th>rentalAssistanceAmount</th>\n",
       "      <th>repairAssistanceEligible</th>\n",
       "      <th>repairAmount</th>\n",
       "      <th>replacementAssistanceEligible</th>\n",
       "      <th>replacementAmount</th>\n",
       "      <th>sbaEligible</th>\n",
       "      <th>primaryResidence</th>\n",
       "      <th>personalPropertyEligible</th>\n",
       "      <th>ppfvl</th>\n",
       "      <th>haAmount</th>\n",
       "      <th>haAmount_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>censusTractId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34031236602.0</th>\n",
       "      <td>1</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001020100.0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001020200.0</th>\n",
       "      <td>2</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001020300.0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001020400.0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001020502.0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001020802.0</th>\n",
       "      <td>1</td>\n",
       "      <td>18768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001021000.0</th>\n",
       "      <td>2</td>\n",
       "      <td>15744.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001021101.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37001021201.0</th>\n",
       "      <td>1</td>\n",
       "      <td>51948.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id grossIncome householdComposition specialNeeds  \\\n",
       "              count        mean                 mean          sum   \n",
       "censusTractId                                                       \n",
       "34031236602.0     1    130000.0                  1.0            0   \n",
       "37001020100.0     2         NaN                  1.5            1   \n",
       "37001020200.0     2     13500.0                  2.5            0   \n",
       "37001020300.0     1         NaN                  1.0            0   \n",
       "37001020400.0     1         NaN                  1.0            0   \n",
       "37001020502.0     2         1.0                  1.5            0   \n",
       "37001020802.0     1     18768.0                  1.0            0   \n",
       "37001021000.0     2     15744.0                  3.0            0   \n",
       "37001021101.0     1      1553.0                  2.0            0   \n",
       "37001021201.0     1     51948.0                  2.0            0   \n",
       "\n",
       "              homeOwnersInsurance floodInsurance inspected rpfvl  \\\n",
       "                              sum            sum       sum   sum   \n",
       "censusTractId                                                      \n",
       "34031236602.0                   1              1         0   0.0   \n",
       "37001020100.0                   2              0         0   0.0   \n",
       "37001020200.0                   0              0         0   0.0   \n",
       "37001020300.0                   0              0         0   0.0   \n",
       "37001020400.0                   1              0         0   0.0   \n",
       "37001020502.0                   0              0         0   0.0   \n",
       "37001020802.0                   0              0         0   0.0   \n",
       "37001021000.0                   0              0         0   0.0   \n",
       "37001021101.0                   0              0         0   0.0   \n",
       "37001021201.0                   0              0         0   0.0   \n",
       "\n",
       "              habitabilityRepairsRequired destroyed waterLevel floodDamage  \\\n",
       "                                      sum       sum       mean         sum   \n",
       "censusTractId                                                                \n",
       "34031236602.0                           1         0        0.0           0   \n",
       "37001020100.0                           2         0        0.0           0   \n",
       "37001020200.0                           2         0        0.0           0   \n",
       "37001020300.0                           1         0        0.0           0   \n",
       "37001020400.0                           1         0        0.0           0   \n",
       "37001020502.0                           2         0        0.0           0   \n",
       "37001020802.0                           1         0        0.0           0   \n",
       "37001021000.0                           2         0        0.0           0   \n",
       "37001021101.0                           1         0        0.0           0   \n",
       "37001021201.0                           1         0        0.0           0   \n",
       "\n",
       "              foundationDamage foundationDamageAmount roofDamage  \\\n",
       "                           sum                    sum        sum   \n",
       "censusTractId                                                      \n",
       "34031236602.0                0                    0.0          0   \n",
       "37001020100.0                0                    0.0          0   \n",
       "37001020200.0                0                    0.0          0   \n",
       "37001020300.0                0                    0.0          0   \n",
       "37001020400.0                0                    0.0          0   \n",
       "37001020502.0                0                    0.0          0   \n",
       "37001020802.0                0                    0.0          0   \n",
       "37001021000.0                0                    0.0          0   \n",
       "37001021101.0                0                    0.0          0   \n",
       "37001021201.0                0                    0.0          0   \n",
       "\n",
       "              roofDamageAmount tsaEligible tsaCheckedIn  \\\n",
       "                           sum         sum          sum   \n",
       "censusTractId                                             \n",
       "34031236602.0              0.0           0            0   \n",
       "37001020100.0              0.0           0            0   \n",
       "37001020200.0              0.0           0            0   \n",
       "37001020300.0              0.0           0            0   \n",
       "37001020400.0              0.0           0            0   \n",
       "37001020502.0              0.0           0            0   \n",
       "37001020802.0              0.0           0            0   \n",
       "37001021000.0              0.0           0            0   \n",
       "37001021101.0              0.0           0            0   \n",
       "37001021201.0              0.0           0            0   \n",
       "\n",
       "              rentalAssistanceEligible rentalAssistanceAmount  \\\n",
       "                                   sum                    sum   \n",
       "censusTractId                                                   \n",
       "34031236602.0                        0                    0.0   \n",
       "37001020100.0                        0                    0.0   \n",
       "37001020200.0                        0                    0.0   \n",
       "37001020300.0                        0                    0.0   \n",
       "37001020400.0                        0                    0.0   \n",
       "37001020502.0                        0                    0.0   \n",
       "37001020802.0                        0                    0.0   \n",
       "37001021000.0                        0                    0.0   \n",
       "37001021101.0                        0                    0.0   \n",
       "37001021201.0                        0                    0.0   \n",
       "\n",
       "              repairAssistanceEligible repairAmount  \\\n",
       "                                   sum          sum   \n",
       "censusTractId                                         \n",
       "34031236602.0                        0          0.0   \n",
       "37001020100.0                        0          0.0   \n",
       "37001020200.0                        0          0.0   \n",
       "37001020300.0                        0          0.0   \n",
       "37001020400.0                        0          0.0   \n",
       "37001020502.0                        0          0.0   \n",
       "37001020802.0                        0          0.0   \n",
       "37001021000.0                        0          0.0   \n",
       "37001021101.0                        0          0.0   \n",
       "37001021201.0                        0          0.0   \n",
       "\n",
       "              replacementAssistanceEligible replacementAmount sbaEligible  \\\n",
       "                                        sum               sum         sum   \n",
       "censusTractId                                                               \n",
       "34031236602.0                             0               0.0           0   \n",
       "37001020100.0                             0               0.0           0   \n",
       "37001020200.0                             0               0.0           0   \n",
       "37001020300.0                             0               0.0           0   \n",
       "37001020400.0                             0               0.0           0   \n",
       "37001020502.0                             0               0.0           0   \n",
       "37001020802.0                             0               0.0           0   \n",
       "37001021000.0                             0               0.0           0   \n",
       "37001021101.0                             0               0.0           0   \n",
       "37001021201.0                             0               0.0           0   \n",
       "\n",
       "              primaryResidence personalPropertyEligible ppfvl haAmount  \\\n",
       "                           sum                      sum   sum      sum   \n",
       "censusTractId                                                            \n",
       "34031236602.0                0                        0   0.0      0.0   \n",
       "37001020100.0                2                        0   0.0      0.0   \n",
       "37001020200.0                2                        0   0.0      0.0   \n",
       "37001020300.0                1                        0   0.0      0.0   \n",
       "37001020400.0                1                        0   0.0      0.0   \n",
       "37001020502.0                2                        0   0.0      0.0   \n",
       "37001020802.0                1                        0   0.0      0.0   \n",
       "37001021000.0                2                        0   0.0      0.0   \n",
       "37001021101.0                1                        0   0.0      0.0   \n",
       "37001021201.0                1                        0   0.0      0.0   \n",
       "\n",
       "              haAmount_predicted  \n",
       "                             sum  \n",
       "censusTractId                     \n",
       "34031236602.0                0.0  \n",
       "37001020100.0                0.0  \n",
       "37001020200.0                0.0  \n",
       "37001020300.0                0.0  \n",
       "37001020400.0                0.0  \n",
       "37001020502.0                0.0  \n",
       "37001020802.0                0.0  \n",
       "37001021000.0                0.0  \n",
       "37001021101.0                0.0  \n",
       "37001021201.0                0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', str)\n",
    "femaTestData_CensusTract.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write aggregated predictions\n",
    "femaTestData_CensusTract.to_csv(\"./predictions/FEMA-Large-NC-clean-predictions-censusTract.csv\", index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
